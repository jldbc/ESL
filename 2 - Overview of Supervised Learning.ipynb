{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Overview of Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - 2.2 Introduction, Variables Types and Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised learning** is the practice of using input values to predict output values. For each observation, there is a corresponding target value. Using our observations we can learn patterns of how various input features change in relation to the output. The output is a numerical measurement where each value is either larger, smaller, or equal to another (i.e. there is explicit ordering to the output). \n",
    "\n",
    "#### Terminology\n",
    "* Predicting quantitative output: regression\n",
    "* Predicting qualitative (class) output: classification\n",
    "* Variable types: quantitative (1,3.3,7), qualitative(\"red\",\"green\",\"blue\"), ordered qualitative (e.g. \"small\", \"medium\", \"large\")\n",
    "\n",
    "#### Ways to represent qualitative data\n",
    "* 0/1 or -1/1\n",
    "* \"Binary\" or \"dummy\" variables\n",
    "* N qualitative values to a variables => N different binary dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Two Simple Approaches to Prediciton: Least Squares and Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two simple but powerful methods for prediction: least squares (a linear best fit model) and nearest neighbors. The former makes heavy assumptions about the structure of the data, while the latter makes none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models and Least Squares\n",
    "\n",
    "The linear model has been a mainstay of statistics for the past several decades and remains one of its most important tools. Given a vectors of inputs $X^T = (X_1, X_2, ... X_p),$ the output $Y$ is predicted via the model\n",
    "\n",
    "$$ \\hat{Y} = \\hat{\\beta}_0 + \\sum_{j=1}^p X_{j}\\hat{\\beta}_j .$$\n",
    "\n",
    "The term $\\hat{\\beta}_0$ is the intercept, also referred to as the **bias**. It is sometimes convenient to include the constant variable 1 in matrix $X$ so that the intercept term can be included in the matrix of coefficients $\\hat{\\beta}.$ When this is done, the linear model can be written as an inner product\n",
    "\n",
    "$$ \\hat{Y} = X^{T}\\hat{\\beta}. $$\n",
    "\n",
    "In this case, $X^T$ is the trainspose of the matrix of our features, $\\hat{Y}$ is a vector with one entry per observation on the data set, and $\\hat{\\beta}$ is a p x 1 vector of coefficients. \n",
    "\n",
    "The most popular way to fit this model is to do so by **least squares**. That is, to locate the set of coefficients $\\beta$ that minimize the sum of squared residuals (\"residual sum of squares\", or **RSS**)\n",
    "\n",
    "$$ RSS(\\beta) = \\sum_{1}^n (y_i - \\hat{y}_i)^2.$$\n",
    "\n",
    "Characterized in matrix notation, this becomes\n",
    "\n",
    "$$ RSS(\\beta) = (y - X\\beta)^T (y - X\\beta).$$\n",
    "\n",
    "Differentiating w.r.t. \\beta gives the normal equations \n",
    "\n",
    "$$ X^T (y - X\\beta) = 0. $$\n",
    "\n",
    "If $X^T X$ is nonsingular, we get the unique solution\n",
    "\n",
    "$$ \\hat{\\beta} = (X^{T}X)^{-1}X^{T}y.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: solving OLS \"by hand\" (by numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: [[ 293.28437125]\n",
      " [   8.71021975]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVbBxOQqcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10713e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matrix X will range 0 to 100 with an added bias column of all ones\n",
    "X = np.linspace(0,100,100)\n",
    "x_beta = np.linspace(1,1,100)\n",
    "X = np.concatenate(([x_beta],[X]),axis=0).T # add the bias column to X\n",
    "\n",
    "# Y will be the true function of 8.6x + 300, with added gaussian noise\n",
    "y = np.matrix(300 + 8.6*X[:,1]).T + np.matrix(np.random.normal(0,50,100)).T \n",
    "\n",
    "# solve for beta\n",
    "beta = np.dot(np.linalg.pinv(np.dot(X.T,X)), np.dot(X.T,y))\n",
    "print(\"Beta: {}\".format(beta))\n",
    "\n",
    "#make predictions\n",
    "yhat = np.dot(X,beta)\n",
    "\n",
    "plt.scatter(np.asarray(X[:,1]),np.asarray(yhat),color='blue')\n",
    "plt.scatter(np.asarray(X[:,1]),np.asarray(y),color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"true\" intercept and slope are 300 and 8.6. Least squares comes pretty close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest-Neighbor Methods\n",
    "\n",
    "Nearest neighbors methods use the training observations closest to $x_i$ in order to form $\\hat{y}_i.$ The **K-Nearest  Neighbors (KNN)** model is defined as \n",
    "\n",
    "$$ \\hat{Y} = \\frac{1}{k} \\sum_{x_i \\in N_k(x)} y_i,$$\n",
    "\n",
    "where $N_k(x)$ is the neighborhood of $x$ defined by its $k$ closest points by some measure of distance. Euclidean distance works fine as a simple and interpretable metric, but in higher dimensions other metrics may become desirable. The model, then, is simply the average of the target values associated with each point's $k$ nearest observations.\n",
    "\n",
    "Intuitively, within sample, decreasing the value of K will improve the accuracy of the model. In the extreme case, k=1 provides perfect overfitting where y is always set equal to itself. Out of sample, however, this would clearly lead to overfitting. It is necessary, then, to test various values of K to see which best balances model accuracy and out of sample generalization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Statistical Decision Theory\n",
    "\n",
    "Given that:\n",
    "\n",
    "* $ X \\in \\mathbb{R}^p $ (X a real valued input vector)\n",
    "* $ Y \\in \\mathbb{R} $ (Y a real valued output vector)\n",
    "* X and Y have joint ditribution $ Pr(X,Y) $\n",
    "\n",
    "Our goal is to find a function $f(X)$ for predicting $Y$ given the values of input $X$.\n",
    "\n",
    "This theory requires a loss function $L(Y,f(X))$ to tell us how close to the true $Y$ our predicted output $\\hat{Y}$ is and to penalize prediction errors. The most common such function os the **squared error loss**: $L(Y,f(X)) = (Y-f(X))^2.$ \n",
    "\n",
    "Our goal, then, is to find the function $f(X)$ that minimizes the expected prediction error (EPE). In this case is the conditional expectation of $Y$ given $X$\n",
    "\n",
    "$$ f(X) = E(Y | X = x), $$\n",
    "\n",
    "also known as the **regression function**.\n",
    "\n",
    "The best prediction of $Y$ at any point $X=x$, then, when determining \"best\" by mean squared error, is the conditional average.\n",
    "\n",
    "**Nearest Neighbors** methods can be seen as an attempt to directly implement this with the training data, taking the average of all $y_i$ points in the neighborhood of each $x_i,$ written as:\n",
    "\n",
    "$$ \\hat{f(X)} = \\text{Ave}(y_i | x_i \\in N_{k}(X)), $$\n",
    "\n",
    "where $N_{k}(X)$ is still the neighborhood of k points closest to $x_i$ by some similarity measure. Two approximations are happening here:\n",
    "\n",
    "* Expectation is approximated by averaging over sample data\n",
    "* Conditioning at a point is relaxed to conditioning on some region \"close enough\" to a target point.\n",
    "\n",
    "Some important properties of this:\n",
    "\n",
    "* As $ N \\to \\infty, \\text{ } L(Y,f(X))$ decreases \n",
    "* As $ k $ increases, the stability of the estimator improves\n",
    "* As $ k,N \\to \\infty \\text{ } s.t. \\frac{k}{N} \\to 0, \\text{ } \\hat{f}(X) \\to E(Y|X=x) $\n",
    "\n",
    "This last property is certainly exciting, but keep in mind that our datasets are never infinitely large, and therefore this is of course not a perfect estimator. In fact, linear or otherwise more-structured models will often prove to be more stable estimators than k-nearest neighbors. KNN also has the problem that its instability worsens as the dimensionality $p$ increases, which proves problematic in many real-world applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: solving KNN \"by hand\" (by numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (continue here later with the section connecting the two methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ### 2.5 Local Methods in High Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.6 Statistical Models, Supervised Learning, and Function Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
